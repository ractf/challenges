diff --git a/main.py b/main.py
old mode 100644
new mode 100755
index e01d074..2e9c316
--- a/main.py
+++ b/main.py
@@ -1,3 +1,4 @@
+#!/usr/bin/env python3
 # encoding: utf-8
 """
 @author: yongzhi li
@@ -33,6 +34,8 @@ from models.HidingUNet import UnetGenerator
 from models.RevealNet import RevealNet

 DATA_DIR = '/n/liyz/data/deep-steganography-dataset/'
+imsg_1 = 1024
+imsg_2 = 2048

 parser = argparse.ArgumentParser()
 parser.add_argument('--dataset', default="train",
@@ -41,7 +44,7 @@ parser.add_argument('--workers', type=int, default=8,
                     help='number of data loading workers')
 parser.add_argument('--batchSize', type=int, default=32,
                     help='input batch size')
-parser.add_argument('--imageSize', type=int, default=256,
+parser.add_argument('--imageSize', type=int, default=1024,
                     help='the number of frames')
 parser.add_argument('--niter', type=int, default=100,
                     help='number of epochs to train for')
@@ -178,14 +181,14 @@ def main():
         train_dataset = MyImageFolder(
             traindir,  # 对数据进行预处理
             transforms.Compose([  # 将几个transforms 组合在一起
-                transforms.Resize([opt.imageSize, opt.imageSize]),  # 随机切再resize成给定的size大小
+                transforms.Resize([imsg_1, imsg_2]),  # 随机切再resize成给定的size大小
                 transforms.ToTensor(),
                 # 把一个取值范围是[0,255]或者shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor
             ]))
         val_dataset = MyImageFolder(
             valdir,  # 对数据进行预处理
             transforms.Compose([  # 将几个transforms 组合在一起
-                transforms.Resize([opt.imageSize, opt.imageSize]),  # 随机切再resize成给定的size大小
+                transforms.Resize([imsg_1, imsg_2]),  # 随机切再resize成给定的size大小
                 transforms.ToTensor(),  # 把一个取值范围是[0,255]或者shape为(H,W,C)的numpy.ndarray，
                 # 转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor
             ]))
@@ -198,7 +201,7 @@ def main():
         test_dataset = MyImageFolder(
             testdir,  # 对数据进行预处理
             transforms.Compose([  # 将几个transforms 组合在一起
-                transforms.Resize([opt.imageSize, opt.imageSize]),  # 随机切再resize成给定的size大小
+                transforms.Resize([imsg_1, imsg_2]),  # 随机切再resize成给定的size大小
                 transforms.ToTensor(),
                 # 把一个取值范围是[0,255]或者shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0,1.0]的torch.FloadTensor
             ]))
@@ -209,23 +212,24 @@ def main():
     #                      norm_layer=nn.BatchNorm2d, use_dropout=False)

     Hnet = UnetGenerator(input_nc=6, output_nc=3, num_downs=7, output_function=nn.Sigmoid)
-    Hnet.cuda()
-    Hnet.apply(weights_init)
     # 判断是否接着之前的训练
     if opt.Hnet != "":
-        Hnet.load_state_dict(torch.load(opt.Hnet))
+        Hnet.apply(weights_init)
+        Hnet.load_state_dict(torch.load(opt.Hnet, map_location=torch.device('cpu')))
     # 两块卡加这行
     if opt.ngpu > 1:
+        Hnet.cuda()
+        Hnet.apply(weights_init)
         Hnet = torch.nn.DataParallel(Hnet).cuda()
     print_network(Hnet)

     ################   获得Reveal网络的对象  ################
     Rnet = RevealNet(output_function=nn.Sigmoid)
-    Rnet.cuda()
-    Rnet.apply(weights_init)
     if opt.Rnet != '':
-        Rnet.load_state_dict(torch.load(opt.Rnet))
+        Rnet.apply(weights_init)
+        Rnet.load_state_dict(torch.load(opt.Rnet, map_location=torch.device('cpu')))
     if opt.ngpu > 1:
+        Rnet.cuda()
         Rnet = torch.nn.DataParallel(Rnet).cuda()
     print_network(Rnet)

@@ -449,7 +453,7 @@ def test(test_loader, epoch, Hnet, Rnet, criterion):
         Hnet.zero_grad()
         Rnet.zero_grad()
         all_pics = data  # allpics contian cover_img and secret_img ,label is not needed
-        this_batch_size = int(all_pics.size()[0] / 2)  # in order to handle the final batch which may not have opt.size
+        this_batch_size = int(all_pics.size()[0] / 2)  # in order to handle the final batch which may not have opt.size[]

         # half of the front is as cover_img ，half of the end is as secret_img
         cover_img = all_pics[0:this_batch_size, :, :, :]  # batchSize,3,256,256
@@ -459,23 +463,28 @@ def test(test_loader, epoch, Hnet, Rnet, criterion):
         concat_img = torch.cat([cover_img, secret_img], dim=1)

         # data into GPU
-        if opt.cuda:
+        if opt.cuda and False:
             cover_img = cover_img.cuda()
             secret_img = secret_img.cuda()
             concat_img = concat_img.cuda()

-        concat_imgv = Variable(concat_img, volatile=True)  # concat_img is the input of Hiding net
-        cover_imgv = Variable(cover_img, volatile=True)  # cover_imgv is the label of Hiding net
+        with torch.no_grad():
+            concat_imgv = Variable(concat_img) #, volatile=True)  # concat_img is the input of Hiding net
+            cover_imgv = Variable(cover_img) #, volatile=True)  # cover_imgv is the label of Hiding net

         container_img = Hnet(concat_imgv)  # concat_img as the input of HidingNet and get the container_img
         errH = criterion(container_img, cover_imgv)  # Hiding net reconstructed error
-        Hlosses.update(errH.data[0], this_batch_size)  # record the H loss value
+        Hlosses.update(errH.item(), this_batch_size)  # record the H loss value

+        # WHERE SECRET IMAGE IS NOT AVAILABLE, IT MUST BE COPIED INSIDE ./example_pics WITH A SLIGHTLY DIFFERENT NAME
+        # THEN RNET MUST BE POINTED TO THE COVER IMAGE NOT THE SECRET IMAGE!!
         rev_secret_img = Rnet(
-            container_img)  # containerImg is the input of the Rnet and get the output "rev_secret_img"
-        secret_imgv = Variable(secret_img, volatile=True)  # secret_imgv is the label of Rnet
+            Variable(cover_img))  # containerImg is the input of the Rnet and get the output "rev_secret_img"
+        print("container: ", container_img, "\n\nsecret_img: ", secret_img)
+        with torch.no_grad():
+            secret_imgv = Variable(secret_img) #, volatile=True)  # secret_imgv is the label of Rnet
         errR = criterion(rev_secret_img, secret_imgv)  # Reveal net reconstructed error
-        Rlosses.update(errR.data[0], this_batch_size)  # record the R loss value
+        Rlosses.update(errR.item(), this_batch_size)  # record the R loss value
         save_result_pic(this_batch_size, cover_img, container_img.data, secret_img, rev_secret_img.data, epoch, i,
                         opt.testPics)

@@ -512,16 +521,18 @@ def print_log(log_info, log_path, console=True):
 # save result pic and the coverImg filePath and the secretImg filePath
 def save_result_pic(this_batch_size, originalLabelv, ContainerImg, secretLabelv, RevSecImg, epoch, i, save_path):
     if not opt.debug:
-        originalFrames = originalLabelv.resize_(this_batch_size, 3, opt.imageSize, opt.imageSize)
-        containerFrames = ContainerImg.resize_(this_batch_size, 3, opt.imageSize, opt.imageSize)
-        secretFrames = secretLabelv.resize_(this_batch_size, 3, opt.imageSize, opt.imageSize)
-        revSecFrames = RevSecImg.resize_(this_batch_size, 3, opt.imageSize, opt.imageSize)
+        originalFrames = originalLabelv.resize_(this_batch_size, 3, imsg_1, imsg_2)
+        containerFrames = ContainerImg.resize_(this_batch_size, 3, imsg_1, imsg_2)
+        secretFrames = secretLabelv.resize_(this_batch_size, 3, imsg_1, imsg_2)
+        revSecFrames = RevSecImg.resize_(this_batch_size, 3, imsg_1, imsg_2)

         showContainer = torch.cat([originalFrames, containerFrames], 0)
         showReveal = torch.cat([secretFrames, revSecFrames], 0)
         # resultImg contains four rows，each row is coverImg containerImg secretImg RevSecImg, total this_batch_size columns
         resultImg = torch.cat([showContainer, showReveal], 0)
         resultImgName = '%s/ResultPics_epoch%03d_batch%04d.png' % (save_path, epoch, i)
+        vutils.save_image(containerFrames, f"{save_path}/thumb.png")
+        vutils.save_image(revSecFrames, f"{save_path}/revsec_thumb.png")
         vutils.save_image(resultImg, resultImgName, nrow=this_batch_size, padding=1, normalize=True)


